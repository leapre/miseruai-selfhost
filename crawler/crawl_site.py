#!/usr/bin/env python3
"""
ã‚µã‚¤ãƒˆãƒžãƒƒãƒ—ã‚’å†å¸°çš„ã«ãŸã©ã‚Šã€æœ¬æ–‡ã‚’ trafilatura ã§æŠ½å‡ºã—ã¦
data/corpus.jsonl ã«ä¿å­˜ã™ã‚‹ã€‚
BASE URL ã¯ (å„ªå…ˆåº¦) argv1 > ç’°å¢ƒå¤‰æ•° SITE_BASE > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
"""
import os, sys, json, pathlib, requests, tqdm, trafilatura, xml.etree.ElementTree as ET

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE = (
    sys.argv[1]                    # 1. ã‚³ãƒžãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°
    if len(sys.argv) > 1 else
    os.getenv("SITE_BASE")         # 2. Workflow ã‹ã‚‰æ¸¡ã™ç’°å¢ƒå¤‰æ•°
    or "https://example.com"       # 3. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ (ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆç”¨)
)
SITEMAP_URL = f"{BASE.rstrip('/')}/sitemap.xml"
OUT_FILE    = pathlib.Path("data/corpus.jsonl")
OUT_FILE.parent.mkdir(exist_ok=True)

# â”€â”€â”€â”€â”€ ã‚µã‚¤ãƒˆãƒžãƒƒãƒ—å†å¸°å–å¾— â”€â”€â”€â”€â”€
def parse_sitemap(url: str) -> list[str]:
    xml_text = requests.get(url, timeout=10).text
    root = ET.fromstring(xml_text)
    locs = [loc.text for loc in root.iterfind(".//{*}loc")]

    if root.tag.endswith("sitemapindex"):
        urls = []
        for child in locs:
            urls.extend(parse_sitemap(child))   # å†å¸°
        return urls
    return locs

# â”€â”€â”€â”€â”€ ãƒ¡ã‚¤ãƒ³å‡¦ç† â”€â”€â”€â”€â”€
if __name__ == "__main__":
    urls = parse_sitemap(SITEMAP_URL)
    print(f"ðŸŒ {len(urls)} URLs found @ {BASE}")

    with OUT_FILE.open("w", encoding="utf-8") as fh:
        for url in tqdm.tqdm(urls, desc="crawl"):
            html = trafilatura.fetch_url(url)
            if not html:
                continue
            text = trafilatura.extract(html, include_comments=False, include_tables=False)
            if text and len(text) > 200:
                fh.write(json.dumps({"url": url, "text": text}, ensure_ascii=False) + "\n")

    size_kb = OUT_FILE.stat().st_size / 1024
    print(f"âœ… saved {OUT_FILE.resolve()} ({size_kb:.1f} KB)")

